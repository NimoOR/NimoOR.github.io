<!DOCTYPE html>
<html lang = "en">
  <head>
    <title>AI</title>
    <meta charset="utf-8">
    <link rel="stylesheet" href="https://codermerlin.com/users/nimrod-ohayon-rozanes/DigitalPortfolio/css/index.css">
    <style>
      .p {
	  line-height: 150%;
      }
      .button{
	  display: block;
	  border: none;
	  padding: 0x 32px;
	  text-align: center;
	  text-decoration: none;
	  display: inline-block;
	  font-size: 130;
	  font-family: American Typewriter, serif;
	  margin: 4px 2px;
	  transition-duration: 0.4s;
	  cursor: pointer;
      }
      .genericButtons{
	  display: block;
	  background-color: black;
	  color: white;
	  border:  2px black;
      }
      .genericButtons:hover {
	  display: block;
	  background-color: white;
	  color: black;
	  border: 2px white;
      }
    </style>
  </head>
  <body>
    <div class = "titleBox">
      <h2>
	AI Sentience and Its Consequences
      </h2>
    </div>
    <p>
      Before one can proper evaluate the possible consequances of a sentient AI, one must first consider the meaning of sentience. I argue that first and foremost, sentience, or possing sentience, is the ability to create Qualia. Qualia, as defined by philosophy of the mind, are singular subjective experiences that are functionally irreplicable, in common parlance you might refer to it as "lived experience". There are many doubts on whether this can even apply for AI, after all, AI can never truly be subjective, the experience is produced by sechmatics and all data is repplicable. However, if one supercedes those worried than the question becomes what might occur after an object recieves sentience? what are the consequences?
    </p>
    <p>
      As defined prior, sentience involves the subjective experience of the object, and if AI acheives subjective experience, it creates an ego. The center of subjective experience is the self, or ego. If an AI creates an ego it can percieve the world in terms of itself and others, as opposed to percieving the world in numbers. To compare this to our own, human, condition, although we percieve the world in light refractions and sounds, we exist in terms of me, you, us, them. This thinking is what allows humans to think of themselves, of their own best interest, it is what creates individual personalities, and those experiences are also what makes life valuable. 
    </p>
    <p>
      Think of, for example, murder. Why is it wrong? Murder is essentially wrong because one is violating anothers qualia. We stop others from murdering because we want to protect the qualia , or the lived experience of others. When AI achieves sentience, should we be inclined to protect it's lived experience as well? Morally, sentient AI is a horrific complication. 
    </p>
    <p>
      Ultimatly, the discussion is hardly about the morality of AI. The more important, and relevent aspect of sentient AI is its immidiate consequances to humanity. Personally, I think that sentient AI will largely be benificial to humanity, with some major considerations albiet. Sentient AI could make choices that are outside of what it is programmed from (an important destinction from Machine Learning algorithem is that when confronted with a scenario in outside of its training data, it will be unable to properly adapt). This is hugely useful for emulating humans where they are necessary. We've seen time and time again the almost certain inadequacies of self driving cars. While they operate fine in calm empty areas, they make dangerous mistakes, such as going into train lanes (<a href="https://www.youtube.com/watch?v=sbSDsbDQjSU">seen here</a>), and even worse, they are very very far away from being able to operate in dense areas. A sentient AI, who is capable of learning how to drive a car just as a human would learn to drive a car, would be able to drive much more accuratly. 
    </p>
    <p>
      Another benefit of sentient AI, which is independent of the philosophical question of sentience, but rather dependent on the apperance of it's sentience is the ability to interact with humans more smoothly. Human machine interaction between a sophisticated machine and unsophisticated human is incredibly difficult. We've long since flirted with the concept of intelligent assistance with applications like siri and alexa becoming benign, but the programs are still limited in their scope and intelligence. Sentiente AI, or AI that would appear to be sentient would be a huge step foreward in smoother operation of technologies. 
    </p>
    <p>
      Despite the practicalities of Sentient AI, we have to consider some of the drawbacks, and the potential consequances. As stated prior, we become responsible for the maintance of a senteint AI on moral grounds; just as we are responsible for a human child. This is of course debatable and beyond the scope of this paper as to what forms of sentience are worthwhile, and if senteint AI would be closer to an animal or human. A much more serious consideration is the future implication of the AI. Sentience, by the property of being sentient, implies the ability to be self interested. This, prior to the invention of sentient AI, is impossible for a machine to do. It can replicate the appearance of self interest, but it can not disobey a properly authorized operator. The concept of a self interested AI conjures up the likes of science fiction, such as the depcition of HAL in A Space Odyssey, or AI from the Matrix, but the question is not unreasonable. Given a self interested AI, will they feel any loyalty towards their human makers?  
    </p>
    <p>
      The question of a hostile robotic take over is still far away, considering we have not yet had a robot successfully push past the turing test, and that the concept of automated sentience is philosophically dodgy at best. Still, it is worth considering the risk and reward of creating what might be our replacement. 
    </p>
    <button class="button genericButtons" onclick = "location.href = ../index/index.html'">back</button>
    </body>
</html>
