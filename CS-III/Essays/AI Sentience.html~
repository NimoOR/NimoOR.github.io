<!DOCTYPE html>
<html lang = "en">
  <head>
    <title>AI</title>
    <meta charset="utf-8">
    <link rel="stylesheet" href="../css/index.css">
    <style>
      .p {
	  line-height: 150%;
      }
      .button{
	  display: block;
	  border: none;
	  padding: 0px 32px;
	  text-align: center;
	  text-decoration: none;
	  display: inline-block;
	  font-size: 130px;
	  font-family: American Typewriter, serif;
	  margin: 4px 2px;
	  transition-duration: 0.4s;
	  cursor: pointer;
      }
      .genericButtons{
	  display: block;
	  background-color: white;
	  color: black;
	  border:  2px white;
      }
      .genericButtons:hover {
	  display: block;
	  background-color: black;
	  color: white;
	  border: 2px black;
      }
    </style>
  </head>
  <body>
    <div class = "titleBox">
      <h2>
	AI Sentience and Its Consequences
      </h2>
    </div>
    <p>
    Before one can properly evaluate the possible consequences of a sentient AI, one must first consider the meaning of sentience. I argue that first and foremost, sentience, or possing sentience, is the ability to create Qualia. Qualia, as defined by the philosophy of the mind, are singular subjective experiences that are functionally irreplicable, in common parlance you might refer to it as "lived experience". There are many doubts on whether this can even apply to AI, after all, AI can never truly be subjective, the experience is produced by schematics and all data is replicable. However, if one supersedes those worried then the question becomes what might occur after an object receives sentience? what are the consequences?
  </p>
    <p>
  As defined prior, sentience involves the subjective experience of the object, and if AI achieves subjective experience, it creates an ego. The center of subjective experience is the self or ego. If an AI creates an ego it can perceive the world in terms of itself and others, as opposed to perceiving the world in numbers. To compare this to our own, human, condition, although we perceive the world in light refractions and sounds, we exist in terms of me, you, us, and them. This thinking is what allows humans to think of themselves, and of their own best interests, it is what creates individual personalities, and those experiences are also what makes life valuable.
</p>
<p>
  Think of, for example, murder. Why is it wrong? Murder is essentially wrong because one is violating other qualia. We stop others from murdering because we want to protect the qualia or the lived experience of others. When AI achieves sentience, should we be inclined to protect its lived experience as well? Morally, sentient AI is a horrific complication.
</p>
<p>
  Ultimately, the discussion is hardly about the morality of AI. The more important, and relevant aspect of sentient AI is its immediate consequences for humanity. I think that sentient AI will largely be beneficial to humanity, with some major considerations albeit. Sentient AI could make choices that are outside of what it is programmed from (an important distinction from Machine Learning algorithm is that when confronted with a scenario outside of its training data, it will be unable to properly adapt). This is hugely useful for emulating humans where they are necessary. We've seen time and time again the almost certain inadequacies of self-driving cars. While they operate fine in calm empty areas, they make dangerous mistakes, such as going into train lanes (<a href="https://www.youtube.com/watch?v=sbSDsbDQjSU">seen here</a>), and even worse, they are very very far away from being able to operate in dense areas. A sentient AI, who is capable of learning how to drive a car just as a human would learn to drive a car, would be able to drive much more accurately.
</p>
<p>
  Another benefit of sentient AI, which is independent of the philosophical question of sentience, but rather dependent on the appearance of its sentience is the ability to interact with humans more smoothly. Human-machine interaction between a sophisticated machine and an unsophisticated human is incredibly difficult. We've long since flirted with the concept of intelligent assistance with applications like Siri and Alexa becoming benign, but the programs are still limited in their scope and intelligence. Sentient AI or AI that would appear to be sentient would be a huge step forward in the smoother operation of technologies.
</p>
<p>
  Despite the practicalities of Sentient AI, we have to consider some of the drawbacks, and the potential consequences. As stated prior, we become responsible for the maintenance of a sentient AI on moral grounds; just as we are responsible for a human child. This is of course debatable and beyond the scope of this paper as to what forms of sentience are worthwhile, and if sentient AI would be closer to an animal or human. Much more serious consideration is the future implication of AI. Sentience, by the property of being sentient, implies the ability to be self-interested. This, before the invention of sentient AI, is impossible for a machine to do. It can replicate the appearance of self-interest, but it can not disobey a properly authorized operator. The concept of a self-interested AI conjures up the likes of science fiction, such as the depiction of HAL in A Space Odyssey, or AI from the Matrix, but the question is not unreasonable. Given a self-interested AI, will they feel any loyalty towards their human makers?
</p>
<p>
        The question of a hostile robotic takeover is still far away, considering we have not yet had a robot successfully push past the Turing test, and that the concept of automated sentience is philosophically dodgy at best. Still, it is worth considering the risk and reward of creating what might be our replacement.
</p>
<button class="button genericButtons" onclick = "location.href = ../../index/index.html'">back</button>
    </body>
</html>
